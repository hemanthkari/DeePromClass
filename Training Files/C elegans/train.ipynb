{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDSHatB0VVdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xC7iQDPVJfo"
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import average_precision_score, precision_recall_fscore_support, accuracy_score\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56xhZ1mQVJfx"
      },
      "source": [
        "def save_model(model, path):\n",
        "    tf.saved_model.save(model, path)\n",
        "    # converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
        "    # tflite_model = converter.convert()\n",
        "    # open(path+\".tflite\", \"wb+\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-papYHM0VJf4"
      },
      "source": [
        "drive_path = \"/content/drive/My Drive/Promoter Finding Algorithm/C Elegance/\"\n",
        "train_file_path = drive_path + \"train_data.csv\"\n",
        "\n",
        "df = pd.read_csv(train_file_path)\n",
        "split_data = int(df.shape[0]*0.8)\n",
        "train_data = df[:split_data]\n",
        "test_data = df[split_data:]\n",
        "train_labels = train_data.pop(train_data.columns[0])\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
        "train_data = to_categorical(train_data.values.reshape(train_data.shape[0], 151, 1), num_classes=4)\n",
        "test_labels = test_data.pop(test_data.columns[0])\n",
        "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
        "test_data = to_categorical(test_data.values.reshape(test_data.shape[0], 151, 1), num_classes=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nStHrzJoY0b"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBju3SCtVJf-"
      },
      "source": [
        "# def get_compiled_model():\n",
        "#     cnn_model = tf.keras.Sequential()\n",
        "#     cnn_model.add(tf.keras.layers.Input(batch_shape=(None, 151, 1), name='input'))\n",
        "#     for _ in range(0, 4):\n",
        "#         cnn_model.add(tf.keras.layers.Conv1D(filters=[32, 64, 64, 128, 256][_], kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2'))\n",
        "#         cnn_model.add(tf.keras.layers.BatchNormalization())\n",
        "#         cnn_model.add(tf.keras.layers.Conv1D(filters=[32, 64, 64, 128, 256][_], kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2'))\n",
        "#         cnn_model.add(tf.keras.layers.BatchNormalization())\n",
        "#         cnn_model.add(tf.keras.layers.AvgPool1D(pool_size = 2))\n",
        "#         cnn_model.add(tf.keras.layers.Dropout(0.5))\n",
        "#     cnn_model.add(tf.keras.layers.Flatten())\n",
        "#     lstm_model = tf.keras.Sequential()\n",
        "#     lstm_model.add(tf.keras.layers.TimeDistributed(cnn_model))\n",
        "#     lstm_model.add(tf.keras.layers.LSTM(units=10, activation='relu', return_sequences=False, batch_input_shape=[None, 640]))\n",
        "#     lstm_model.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
        "#     lstm_model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "#     lstm_model.compile(optimizer=tf.optimizers.Adam(0.001), loss=tf.losses.categorical_crossentropy, metrics=['categorical_accuracy'])\n",
        "#     return lstm_model\n",
        "\n",
        "# def get_compiled_model():\n",
        "#     input_layer = tf.keras.layers.Input(batch_shape=(None, 151, 1), name='input')\n",
        "#     conv_layer_1 = tf.keras.layers.Conv1D(filters=32, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(input_layer)\n",
        "#     bn_1 = tf.keras.layers.BatchNormalization()(conv_layer_1)\n",
        "#     conv_layer_2 = tf.keras.layers.Conv1D(filters=32, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_1)\n",
        "#     bn_2 = tf.keras.layers.BatchNormalization()(conv_layer_2)\n",
        "#     avg_pool_1 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_2)\n",
        "#     dp_1 = tf.keras.layers.Dropout(0.5)(avg_pool_1)\n",
        "#     conv_layer_3 = tf.keras.layers.Conv1D(filters=64, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_1)\n",
        "#     bn_3 = tf.keras.layers.BatchNormalization()(conv_layer_3)\n",
        "#     conv_layer_4 = tf.keras.layers.Conv1D(filters=64, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_3)\n",
        "#     bn_4 = tf.keras.layers.BatchNormalization()(conv_layer_4)\n",
        "#     avg_pool_2 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_4)\n",
        "#     dp_2 = tf.keras.layers.Dropout(0.5)(avg_pool_2)\n",
        "#     conv_layer_5 = tf.keras.layers.Conv1D(filters=128, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_2)\n",
        "#     bn_5 = tf.keras.layers.BatchNormalization()(conv_layer_5)\n",
        "#     conv_layer_6 = tf.keras.layers.Conv1D(filters=128, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_5)\n",
        "#     bn_6 = tf.keras.layers.BatchNormalization()(conv_layer_6)\n",
        "#     avg_pool_3 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_6)\n",
        "#     dp_3 = tf.keras.layers.Dropout(0.5)(avg_pool_3)\n",
        "#     flat = tf.keras.layers.Flatten()(dp_3)\n",
        "#     res_1 = tf.keras.layers.Reshape((1, flat.shape[1]))(flat)\n",
        "#     lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=1024, activation='relu', return_sequences=False))(res_1)\n",
        "#     dense_1 = tf.keras.layers.Dense(units=1024, activation='relu')(lstm_1)\n",
        "#     dense_2 = tf.keras.layers.Dense(2, activation='softmax')(dense_1)\n",
        "#     model = tf.keras.models.Model(inputs = input_layer, outputs = dense_2)\n",
        "#     model.compile(optimizer=tf.optimizers.Adam(0.001), loss=tf.losses.categorical_crossentropy, metrics=['categorical_accuracy'])\n",
        "#     model.summary()\n",
        "    \n",
        "    #     model.add(tf.keras.layers.LSTM(units=1024))\n",
        "#     model.add(tf.keras.layers.Dropout(rate=0.25))\n",
        "#     model.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
        "#     model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "#     opt = tf.optimizers.Adam(0.001)\n",
        "#     model.compile(optimizer=opt, loss=tf.losses.categorical_crossentropy, metrics=['categorical_accuracy'])\n",
        "#     model.summary()\n",
        "\n",
        "\n",
        "def get_compiled_model():\n",
        "    input_layer = tf.keras.layers.Input(batch_shape=(None, 151, 4), name='input')\n",
        "    conv_layer_1 = tf.keras.layers.Conv1D(filters=32, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(input_layer)\n",
        "    bn_1 = tf.keras.layers.BatchNormalization()(conv_layer_1)\n",
        "    conv_layer_2 = tf.keras.layers.Conv1D(filters=32, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_1)\n",
        "    bn_2 = tf.keras.layers.BatchNormalization()(conv_layer_2)\n",
        "    avg_pool_1 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_2)\n",
        "    dp_1 = tf.keras.layers.Dropout(0.5)(avg_pool_1)\n",
        "    conv_layer_3 = tf.keras.layers.Conv1D(filters=64, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_1)\n",
        "    bn_3 = tf.keras.layers.BatchNormalization()(conv_layer_3)\n",
        "    conv_layer_4 = tf.keras.layers.Conv1D(filters=64, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_3)\n",
        "    bn_4 = tf.keras.layers.BatchNormalization()(conv_layer_4)\n",
        "    avg_pool_2 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_4)\n",
        "    dp_2 = tf.keras.layers.Dropout(0.5)(avg_pool_2)\n",
        "    conv_layer_5 = tf.keras.layers.Conv1D(filters=128, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_2)\n",
        "    bn_5 = tf.keras.layers.BatchNormalization()(conv_layer_5)\n",
        "    conv_layer_6 = tf.keras.layers.Conv1D(filters=128, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_5)\n",
        "    bn_6 = tf.keras.layers.BatchNormalization()(conv_layer_6)\n",
        "    avg_pool_3 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_6)\n",
        "    dp_3 = tf.keras.layers.Dropout(0.5)(avg_pool_3)\n",
        "    conv_layer_7 = tf.keras.layers.Conv1D(filters=256, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_3)\n",
        "    bn_7 = tf.keras.layers.BatchNormalization()(conv_layer_7)\n",
        "    conv_layer_8 = tf.keras.layers.Conv1D(filters=256, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_7)\n",
        "    bn_8 = tf.keras.layers.BatchNormalization()(conv_layer_8)\n",
        "    avg_pool_4 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_8)\n",
        "    dp_4 = tf.keras.layers.Dropout(0.5)(avg_pool_4)\n",
        "    # conv_layer_9 = tf.keras.layers.Conv1D(filters=256, kernel_size = 5, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_4)\n",
        "    # bn_9 = tf.keras.layers.BatchNormalization()(conv_layer_9)\n",
        "    # conv_layer_10 = tf.keras.layers.Conv1D(filters=256, kernel_size = 7, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_9)\n",
        "    # bn_10 = tf.keras.layers.BatchNormalization()(conv_layer_10)\n",
        "    # avg_pool_5 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_10)\n",
        "    # dp_5 = tf.keras.layers.Dropout(0.5)(avg_pool_5)\n",
        "    flat_1 = tf.keras.layers.Flatten()(dp_4)\n",
        "    res_1 = tf.keras.layers.Reshape((1, flat_1.shape[1]))(flat_1)\n",
        "    lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=1024, activation='relu', return_sequences=False))(res_1)\n",
        "    flat_2 = tf.keras.layers.Flatten()(lstm_1)\n",
        "    dense_1 = tf.keras.layers.Dense(units=1024, activation='relu')(flat_2)\n",
        "    dense_2 = tf.keras.layers.Dense(2, activation='softmax')(dense_1)\n",
        "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_2)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(0.001), loss=tf.losses.categorical_crossentropy, metrics=['categorical_accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2KWj3rPVJgO"
      },
      "source": [
        "model = get_compiled_model()\n",
        "# model = tf.keras.models.load_model(\"model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2NtMsrmVJgU"
      },
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_categorical_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [early, redonplat, tf.keras.callbacks.TensorBoard('logs')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnTexQxoVJgZ"
      },
      "source": [
        "model.fit(train_data, train_labels_cat, epochs=100, validation_split=0.20, batch_size=32, callbacks=callbacks_list, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS4EQpCuVJgd"
      },
      "source": [
        "pred_test = np.argmax(model.predict(test_data), axis = 1)\n",
        "accuracy = accuracy_score(test_labels, pred_test)\n",
        "print(\"Testing Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNexULRBVJgh"
      },
      "source": [
        "cf_m = tf.math.confusion_matrix(test_labels, pred_test, num_classes=2)\n",
        "print(cf_m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlRx_rzVJgk"
      },
      "source": [
        "save_model(model, (drive_path +  \"model\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNmlue7nVJgq"
      },
      "source": [
        "recall = precision_recall_fscore_support(test_labels, pred_test, average=\"binary\")\n",
        "print('Precision: {0:0.2f}'.format(recall[0]))\n",
        "print('Recall: {0:1.2f}'.format(recall[1]))\n",
        "print('F1-Score: {0:2.2f}'.format(recall[2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMhqfna6VJgv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}