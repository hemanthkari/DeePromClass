{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxvKrI-1Spti"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIpJtG2dSAfn"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import average_precision_score, precision_recall_fscore_support, accuracy_score, roc_curve, roc_auc_score\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He1GR9WnSAfu"
      },
      "source": [
        "def save_model(model, path):\n",
        "    tf.saved_model.save(model, path)\n",
        "    # converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
        "    # tflite_model = converter.convert()\n",
        "    # open(path+\".tflite\", \"wb+\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8Q2Qp8SAf2"
      },
      "source": [
        "drive_path = \"/content/drive/My Drive/Promoter Finding Algorithm/Homo Sapiens/\"\n",
        "\n",
        "train_file_path = drive_path + \"train_data.csv\"\n",
        "\n",
        "df = pd.read_csv(train_file_path)\n",
        "split_data = int(df.shape[0]*0.8)\n",
        "train_data = df[:split_data]\n",
        "test_data = df[split_data:]\n",
        "train_labels = train_data.pop(train_data.columns[0])\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
        "train_data = to_categorical(train_data.values.reshape(train_data.shape[0], 151, 1), num_classes=4)\n",
        "test_labels = test_data.pop(test_data.columns[0])\n",
        "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
        "test_data = to_categorical(test_data.values.reshape(test_data.shape[0], 151, 1), num_classes=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW5qAEisSAgG"
      },
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_categorical_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [early, redonplat, tf.keras.callbacks.TensorBoard('logs')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboJq67xSAf9"
      },
      "source": [
        "def get_compiled_model():\n",
        "    input_layer = tf.keras.layers.Input(batch_shape=(None, 151, 4), name='input')\n",
        "    conv_layer_1 = tf.keras.layers.Conv1D(filters=32, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(input_layer)\n",
        "    bn_1 = tf.keras.layers.BatchNormalization()(conv_layer_1)\n",
        "    conv_layer_2 = tf.keras.layers.Conv1D(filters=32, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_1)\n",
        "    bn_2 = tf.keras.layers.BatchNormalization()(conv_layer_2)\n",
        "    avg_pool_1 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_2)\n",
        "    dp_1 = tf.keras.layers.Dropout(0.5)(avg_pool_1)\n",
        "    conv_layer_3 = tf.keras.layers.Conv1D(filters=64, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_1)\n",
        "    bn_3 = tf.keras.layers.BatchNormalization()(conv_layer_3)\n",
        "    conv_layer_4 = tf.keras.layers.Conv1D(filters=64, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_3)\n",
        "    bn_4 = tf.keras.layers.BatchNormalization()(conv_layer_4)\n",
        "    avg_pool_2 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_4)\n",
        "    dp_2 = tf.keras.layers.Dropout(0.5)(avg_pool_2)\n",
        "    conv_layer_5 = tf.keras.layers.Conv1D(filters=128, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_2)\n",
        "    bn_5 = tf.keras.layers.BatchNormalization()(conv_layer_5)\n",
        "    conv_layer_6 = tf.keras.layers.Conv1D(filters=128, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_5)\n",
        "    bn_6 = tf.keras.layers.BatchNormalization()(conv_layer_6)\n",
        "    avg_pool_3 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_6)\n",
        "    dp_3 = tf.keras.layers.Dropout(0.5)(avg_pool_3)\n",
        "    conv_layer_7 = tf.keras.layers.Conv1D(filters=256, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_3)\n",
        "    bn_7 = tf.keras.layers.BatchNormalization()(conv_layer_7)\n",
        "    conv_layer_8 = tf.keras.layers.Conv1D(filters=256, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_7)\n",
        "    bn_8 = tf.keras.layers.BatchNormalization()(conv_layer_8)\n",
        "    avg_pool_4 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_8)\n",
        "    dp_4 = tf.keras.layers.Dropout(0.5)(avg_pool_4)\n",
        "    # conv_layer_9 = tf.keras.layers.Conv1D(filters=256, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(dp_4)\n",
        "    # bn_9 = tf.keras.layers.BatchNormalization()(conv_layer_9)\n",
        "    # conv_layer_10 = tf.keras.layers.Conv1D(filters=256, kernel_size = 3, activation=tf.nn.relu6, strides=1, kernel_regularizer='L1L2')(bn_9)\n",
        "    # bn_10 = tf.keras.layers.BatchNormalization()(conv_layer_10)\n",
        "    # avg_pool_5 = tf.keras.layers.AvgPool1D(pool_size = 2)(bn_10)\n",
        "    # dp_5 = tf.keras.layers.Dropout(0.5)(avg_pool_5)\n",
        "    flat_1 = tf.keras.layers.Flatten()(dp_4)\n",
        "    res_1 = tf.keras.layers.Reshape((1, flat_1.shape[1]))(flat_1)\n",
        "    lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=1024, activation='relu', return_sequences=False))(res_1)\n",
        "    flat_2 = tf.keras.layers.Flatten()(lstm_1)\n",
        "    dense_1 = tf.keras.layers.Dense(units=1024, activation='relu')(flat_2)\n",
        "    dense_2 = tf.keras.layers.Dense(2, activation='softmax')(dense_1)\n",
        "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_2)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(0.001), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['categorical_accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-0hk_6WSAgB"
      },
      "source": [
        "model = get_compiled_model()\n",
        "# model = tf.keras.models.load_model(\"model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKYh4wpeSAgN"
      },
      "source": [
        "model.fit(train_data, train_labels_cat, epochs=100, validation_split=0.20, batch_size=32, callbacks=callbacks_list, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH0vdF6cSAgQ"
      },
      "source": [
        "pred_test = np.argmax(model.predict(test_data), axis = 1)\n",
        "accuracy = accuracy_score(test_labels, pred_test)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cusdRw4zSAgU"
      },
      "source": [
        "cf_m = tf.math.confusion_matrix(test_labels, pred_test, num_classes=2)\n",
        "print(cf_m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYiEk3p6hS4Z"
      },
      "source": [
        "r_c = roc_curve(test_labels, pred_test)\n",
        "roc_sc = roc_auc_score(test_labels, pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p70hyDPAhpml"
      },
      "source": [
        "print(r_c)\n",
        "print(roc_sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkuqTNnVSAgX"
      },
      "source": [
        "save_model(model, drive_path + \"model_homo-sapiens\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lPN0uDuSAgc"
      },
      "source": [
        "recall = precision_recall_fscore_support(test_labels, pred_test, average=\"binary\")\n",
        "print('Precision: {0:0.2f}'.format(recall[0]))\n",
        "print('Recall: {0:1.2f}'.format(recall[1]))\n",
        "print('F1-Score: {0:2.2f}'.format(recall[2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZvRb4eXSAgg"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0yd5T2_SAgk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}